{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \".\"\n",
    "BASE_PATH = Path(BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(base_path, dataset, normal_case=False, constraint_comp=False, l1l2=False, compare_dot_product=False, num_layers_list=None, table=None):\n",
    "    all_data = []\n",
    "\n",
    "    if compare_dot_product:\n",
    "        relevant_norms = [\"1\", \"2\"]\n",
    "    elif dataset == \"sstSubset\":\n",
    "        relevant_norms = [\"1\", \"2\"] if l1l2 else [\"inf\"]\n",
    "    else:\n",
    "        relevant_norms = [\"1\", \"2\", \"inf\"]\n",
    "    \n",
    "    if (dataset == \"sstSubset\" and not normal_case):\n",
    "        netName = f\"bert_smaller\"\n",
    "        size = \"smaller\"\n",
    "    else:\n",
    "        netName = f\"bert_small\"\n",
    "        size = \"small\"\n",
    "        \n",
    "    if dataset == \"sstSubset\" or dataset == \"sst\":\n",
    "        dir = \"sst\"\n",
    "    else:\n",
    "        dir = \"yelp\"\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    num_layers_list = [\"3\", \"6\", \"12\"]\n",
    "    if table == 2:\n",
    "        methods_and_labels = [(\"zonotope\", \"Zonotope-Fast\"), (\"zonotopeSlow\", \"Zonotope-Slow\"), (\"backward\", \"Backward\")]\n",
    "    elif constraint_comp:\n",
    "        methods_and_labels = [(\"zonotopeNoConstraint\", \"Zonotope-Fast-No-Constraint\"), (\"zonotope\", \"Zonotope-Fast\")]\n",
    "    elif compare_dot_product:\n",
    "        methods_and_labels = [(\"zonotopeOtherDotProduct\", \"Zonotope-Fast-OtherDotProduct\"), (\"zonotope\", \"Zonotope-Fast\")]\n",
    "    elif dataset == \"sstSubset\":\n",
    "        if l1l2:\n",
    "            methods_and_labels = [(\"zonotope\", \"Zonotope-Fast\"), (\"baf\", \"BaF\"), (\"backward\", \"Backward\")]\n",
    "        elif normal_case:\n",
    "            methods_and_labels = [(\"zonotope\", \"Zonotope-Fast\"), (\"zonotopeSlow\", \"Zonotope-Slow\"), (\"baf\", \"BaF\")]\n",
    "        else:\n",
    "            methods_and_labels = [(\"zonotope\", \"Zonotope-Fast\"), (\"zonotopeSlow\", \"Zonotope-Slow\"), (\"backward\", \"Backward\"), (\"baf\", \"BaF\")]\n",
    "    else:\n",
    "        methods_and_labels = [(\"baf\", \"BaF\"), (\"zonotope\", \"Zonotope-Fast\")]\n",
    "    \n",
    "    for p in relevant_norms:\n",
    "        for num_layers in num_layers_list:\n",
    "            for method, method_label in methods_and_labels:\n",
    "                if method == \"baf\" or method == \"backward\":\n",
    "                    glob_path = f\"*{dataset}_{dir}_{netName}_{num_layers}_{size}_{method}_{p}_*.csv\"\n",
    "                elif method_label == \"Zonotope-Slow\":\n",
    "                    if dataset == \"sstSubset\" and num_layers == \"12\" and method == \"zonotopeSlow\":\n",
    "                        glob_path = f\"*{dataset}_{dir}_{netName}_{num_layers}_{size}_{method}_{p}_box_7000_WithConstraint_*.csv\"\n",
    "                    else:\n",
    "                        glob_path = f\"*{dataset}_{dir}_{netName}_{num_layers}_{size}_{method}_{p}_box_7000_WithConstraint_*.csv\"\n",
    "                elif method_label == \"Zonotope-Fast\":\n",
    "                    glob_path = f\"*{dataset}_{dir}_{netName}_{num_layers}_{size}_zonotope_{p}_box_14000_WithConstraint_*.csv\"\n",
    "                elif method_label == \"Zonotope-Fast-No-Constraint\":\n",
    "                    glob_path = f\"*{dataset}_{dir}_{netName}_{num_layers}_{size}_zonotope_{p}_box_14000_NoConstraint*.csv\"\n",
    "                elif method_label == \"Zonotope-Fast-OtherDotProduct\":\n",
    "                    glob_path = f\"*{dataset}_{dir}_{netName}_{num_layers}_{size}_zonotope_{p}_box_14000_WithConstraintOtherDotProductOrder_*.csv\"\n",
    "                \n",
    "\n",
    "                \n",
    "                all_files = list(base_path.glob(glob_path))\n",
    "                #print(glob_path)\n",
    "                #print(list(base_path.glob(\"*\")))\n",
    "                #print()\n",
    "                if len(all_files) == 0:\n",
    "                    print(f\"No data for method={method} method_label={method_label} p={p} num_layers={num_layers} glob_path={glob_path}\")\n",
    "                    continue\n",
    "\n",
    "                assert len(all_files) >= 1, f\"*_{num_layers}_small_{method}_{p}_*\"\n",
    "\n",
    "                sorted_files = list(sorted(all_files, key=lambda x: x.stat().st_mtime))\n",
    "                latest_file = sorted_files[-1]\n",
    "                print(method_label, \":\", latest_file)\n",
    "\n",
    "                try:\n",
    "                    df = pd.read_csv(latest_file)\n",
    "                    df['p'] = p\n",
    "                    df['num_layers'] = int(num_layers)\n",
    "                    df['Method'] = method_label\n",
    "                    \n",
    "                    if 'memory' not in df.columns:\n",
    "                        df[\"memory\"] = -1\n",
    "                    \n",
    "                    all_data.append(df)\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    print(f\"Empty CSV file for method={method} p={p} num_layers={num_layers}\")\n",
    "\n",
    "    all_data_df = pd.concat(all_data, ignore_index=True)\n",
    "    all_data_df[\"sentence\"] = pd.to_numeric(all_data_df[\"sentence\"])\n",
    "    all_data_df[\"position\"] = pd.to_numeric(all_data_df[\"position\"])\n",
    "    return all_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BASE_PATH)  # Table 1\n",
    "all_data_df = get_data(BASE_PATH.parent.parent / \"normal_case\" , dataset=\"sst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALLER_NETWORK_RESULTS_PATH = BASE_PATH.parent.parent / 'smaller_network_results'  # Table 2\n",
    "print(SMALLER_NETWORK_RESULTS_PATH.absolute())\n",
    "all_data_smaller_df = get_data(SMALLER_NETWORK_RESULTS_PATH, dataset=\"sstSubset\", table=2)\n",
    "all_data_smaller_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1L2_RESULTS_PATH = BASE_PATH.parent.parent / \"l1l2\"  # Table 3\n",
    "print(L1L2_RESULTS_PATH.absolute())\n",
    "all_data_l1l2_df = get_data(L1L2_RESULTS_PATH, dataset=\"sstSubset\", l1l2=True)\n",
    "all_data_l1l2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_CONSTRAINT_RESULTS_PATH = BASE_PATH.parent.parent / \"no_constraint_results\"  # Table 4\n",
    "print(NO_CONSTRAINT_RESULTS_PATH.absolute())\n",
    "all_data_constraint_comp_df = get_data(NO_CONSTRAINT_RESULTS_PATH, dataset=\"sst\", constraint_comp=True)\n",
    "all_data_constraint_comp_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTHER_DOT_PRODUCT_RESULTS_PATH = BASE_PATH.parent.parent / \"other_dot_product_results\"  # Table 5\n",
    "print(OTHER_DOT_PRODUCT_RESULTS_PATH.absolute())\n",
    "all_data_other_dot_product_df = get_data(OTHER_DOT_PRODUCT_RESULTS_PATH, dataset=\"sst\", compare_dot_product=True)\n",
    "all_data_other_dot_product_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_df):\n",
    "    #print(\"Removing data for sentence #1 (the second sentence!)\")\n",
    "    #data_df = data_df.loc[data_df.sentence != 1]\n",
    "    \n",
    "    try:\n",
    "        data_avg = data_df.groupby(['p', 'num_layers', 'Method'], as_index=False).mean()\n",
    "        data_min = data_df.groupby(['p', 'num_layers', 'Method'], as_index=False).min()\n",
    "        \n",
    "        data_avg = data_avg.drop(columns=[\"sentence\", \"position\"])#.reset_index()\n",
    "        data_min = data_min.drop(columns=[\"sentence\", \"position\"])#.reset_index()\n",
    "        \n",
    "        data_avg = data_avg.sort_values(['p', 'num_layers', 'Method']).astype({'p':\"category\", \"Method\": \"category\", \"num_layers\": \"category\"})\n",
    "        data_min = data_min.sort_values(['p', 'num_layers', 'Method']).astype({'p':\"category\", \"Method\": \"category\", \"num_layers\": \"category\"})\n",
    "\n",
    "        return data_avg, data_min\n",
    "    except Exception as e:\n",
    "        print(f\"Couldn't process dataframe. Exception {e}\")\n",
    "        return None, None\n",
    "\n",
    "data_avg, data_min = process_data(all_data_df)\n",
    "data_avg_smaller, data_min_smaller =  process_data(all_data_smaller_df)\n",
    "data_avg_l1l2, data_min_l1l2 =  process_data(all_data_l1l2_df)\n",
    "data_avg_constraint, data_min_constraint =  process_data(all_data_constraint_comp_df)\n",
    "data_avg_dot_product, data_min_dot_product =  process_data(all_data_other_dot_product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_avg  # Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min  # Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_avg_smaller  # Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min_smaller  # Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_avg_l1l2  # Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min_l1l2  # Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_avg_constraint  # Table 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min_constraint  # Table 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_avg_dot_product    # Table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min_dot_product    # Table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}